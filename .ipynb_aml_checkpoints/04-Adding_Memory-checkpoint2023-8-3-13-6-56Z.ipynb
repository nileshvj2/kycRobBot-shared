{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Memory in LLMs"
      ],
      "metadata": {},
      "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous Notebook 03, we successfully explored how OpenAI models can enhance the results from Azure Cognitive Search. [Bing Chat](http://chat.bing.com/) is a search engine with a GPT-4 model that utilizes the content of search results to provide context and deliver accurate responses to queries.\n",
        "\n",
        "However, we have yet to discover how to engage in a conversation with the LLM. With Bing Chat, this is possible, as the LLM can understand and reference the previous responses.\n",
        "\n",
        "There is a common misconception that GPT models have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
        "\n",
        "The aim of this Notebook is to demonstrate how we can \"provide memory\" to the LLM by utilizing prompts and context."
      ],
      "metadata": {},
      "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
        "from langchain.memory import ConversationBufferMemory, ConversationTokenBufferMemory\n",
        "from openai.error import OpenAIError\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.memory import CosmosDBChatMessageHistory\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils import (\n",
        "    get_search_results,\n",
        "    order_search_results,\n",
        "    model_tokens_limit,\n",
        "    num_tokens_from_docs,\n",
        "    embed_docs,\n",
        "    search_docs,\n",
        "    get_answer,\n",
        ")\n",
        "\n",
        "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_CHAT_PROMPT\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "import logging\n",
        "\n",
        "# Get the root logger\n",
        "logger = logging.getLogger()\n",
        "# Set the logging level to a higher level to ignore INFO messages\n",
        "logger.setLevel(logging.WARNING)\n",
        "\n",
        "DATASOURCE_SAS_TOKEN = \"?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\""
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1693533750981
        }
      },
      "id": "733c782e-204c-47d0-8dae-c9df7091ab23"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1693533754343
        }
      },
      "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's start with the basics\n",
        "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
      ],
      "metadata": {},
      "id": "3dc72b22-11c2-4df0-91b8-033d01829663"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"Tell me some use cases for reinforcement learning?\"\n",
        "FOLLOW_UP_QUESTION = \"Can you summarize your last response?\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1693533773061
        }
      },
      "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "MODEL = \"gpt-35-turbo\"\n",
        "# Create an OpenAI instance\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=1000)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1693533774260
        }
      },
      "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f"
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a very simple prompt template, just the question as is:\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"{question}\",\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1693533777095
        }
      },
      "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see what the GPT model responds\n",
        "response = chain.run(QUESTION)\n",
        "printmd(response)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "1. Game playing: Reinforcement learning has been successfully used to train agents to play games such as chess, Go, and video games.\n\n2. Robotics: Reinforcement learning can be used to train robots to perform tasks, such as grasping objects, navigating through environments, and manipulating objects.\n\n3. Autonomous vehicles: Reinforcement learning can be used to train autonomous vehicles to make decisions while driving, such as when to accelerate, brake, or change lanes.\n\n4. Resource allocation: Reinforcement learning can be used to optimize resource allocation in industries such as manufacturing, logistics, and transportation.\n\n5. Marketing and advertising: Reinforcement learning can be used to optimize marketing and advertising strategies, such as determining the best time to show an ad or the most effective messaging.\n\n6. Finance: Reinforcement learning can be used to optimize investment strategies, such as predicting stock prices or managing portfolios.\n\n7. Healthcare: Reinforcement learning can be used to optimize treatment plans for patients, such as determining the best medication dosage or treatment regimen.\n\n8. Energy management: Reinforcement learning can be used to optimize energy consumption and production, such as controlling the output of wind turbines or solar panels."
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1693533785652
        }
      },
      "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2"
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's ask a follow up question\n",
        "chain.run(FOLLOW_UP_QUESTION)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "\"I'm sorry, as an AI language model, I cannot summarize my previous response without any context. Please provide the necessary information.\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1693533792977
        }
      },
      "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it doesn't remember what it just responded. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2"
    },
    {
      "cell_type": "code",
      "source": [
        "hist_prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"question\"],\n",
        "    template=\"\"\"\n",
        "                {history}\n",
        "                Human: {question}\n",
        "                AI:\n",
        "            \"\"\"\n",
        "    )\n",
        "chain = LLMChain(llm=llm, prompt=hist_prompt)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1693533811333
        }
      },
      "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a"
    },
    {
      "cell_type": "code",
      "source": [
        "Conversation_history = \"\"\"\n",
        "Human: {question}\n",
        "AI: {response}\n",
        "\"\"\".format(question=QUESTION, response=response)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1693533816079
        }
      },
      "id": "6d088e51-e5eb-4143-b87d-b2be429eb864"
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION})"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'Reinforcement learning can be used in various fields such as game playing, robotics, autonomous vehicles, resource allocation, marketing and advertising, finance, healthcare, and energy management to optimize decision-making and improve outcomes.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1693533818400
        }
      },
      "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
      ],
      "metadata": {},
      "id": "045e5af6-55d6-4353-b3f6-3275c95db00a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
      ],
      "metadata": {},
      "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to not duplicate code, we have put many of the code used in Notebook 3 into functions. These functions are in the `common/utils.py` and `common/prompts.py` files This way we can use these functios in the app that we will build later."
      ],
      "metadata": {},
      "id": "d8b27c45-7fbb-40da-a2e3-61e66a8e49b0"
    },
    {
      "cell_type": "code",
      "source": [
        "index1_name = \"cogsrch-index-files\"\n",
        "index2_name = \"cogsrch-index-csv\"\n",
        "indexes = [index1_name, index2_name]\n",
        "\n",
        "agg_search_results = get_search_results(QUESTION, indexes)\n",
        "ordered_results = order_search_results(agg_search_results, reranker_threshold=1)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1692132046242
        }
      },
      "id": "ef9f459b-e8b8-40b9-a94d-80c079968594"
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for key,value in ordered_results.items():\n",
        "    for page in value[\"chunks\"]:\n",
        "        location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
        "        docs.append(Document(page_content=page, metadata={\"source\": location+DATASOURCE_SAS_TOKEN}))\n",
        "\n",
        "# Calculate number of tokens of our docs\n",
        "tokens_limit = model_tokens_limit(MODEL)\n",
        "\n",
        "if(len(docs)>0):\n",
        "    num_tokens = num_tokens_from_docs(docs)\n",
        "    print(\"Custom token limit for\", MODEL, \":\", tokens_limit)\n",
        "    print(\"Combined docs tokens count:\",num_tokens)\n",
        "        \n",
        "else:\n",
        "    print(\"NO RESULTS FROM AZURE SEARCH\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Custom token limit for gpt-35-turbo : 2500\nCombined docs tokens count: 1014\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1692132053218
        }
      },
      "id": "9b2a3595-c3b7-4376-b9c5-0db7a42b3ee4"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if num_tokens > tokens_limit:\n",
        "    index = embed_docs(docs)\n",
        "    top_docs = search_docs(index,QUESTION,k=2)\n",
        "    \n",
        "    # Now we need to recalculate the tokens count of the top results from similarity vector search\n",
        "    # in order to select the chain type: stuff or map_reduce\n",
        "    \n",
        "    num_tokens = num_tokens_from_docs(top_docs)   \n",
        "    print(\"Token count after similarity search:\", num_tokens)\n",
        "    chain_type = \"map_reduce\" if num_tokens > tokens_limit else \"stuff\"\n",
        "    \n",
        "else:\n",
        "    # if total tokens is less than our limit, we don't need to vectorize and do similarity search\n",
        "    top_docs = docs\n",
        "    chain_type = \"stuff\"\n",
        "    \n",
        "print(\"Chain Type selected:\", chain_type)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Chain Type selected: stuff\nCPU times: user 70 µs, sys: 0 ns, total: 70 µs\nWall time: 74.6 µs\n"
        }
      ],
      "execution_count": 13,
      "metadata": {},
      "id": "c26d7540-feb8-4581-849e-003f4bf2a601"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the answer\n",
        "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Reinforcement learning has been used as a practical computational tool for constructing autonomous systems that improve themselves with experience in various applications, such as robotics, industrial manufacturing, and computer game playing <sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[1]</a></sup>. Some use cases include game playing, where reinforcement learning algorithms can be adapted to work for a very general class of games, such as backgammon, which has been used as a test case for reinforcement learning, and robotics, where shaping, local reinforcement signals, imitation, problem decomposition, and reflexes can be used to bias the learning process <sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[1]</a></sup>.",
            "text/plain": "<IPython.core.display.Markdown object>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {},
      "id": "3ce6efa9-2b8f-4810-904d-5986b4ae0372"
    },
    {
      "cell_type": "markdown",
      "source": [
        "And if we ask the follow up question:"
      ],
      "metadata": {},
      "id": "27501f1b-7db0-4ee3-9cb1-e609254ffa3d"
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_answer(llm=llm, docs=top_docs,  query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "I apologize, but your question is not related to any of the provided content. Could you please provide a question related to one of the documents?"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1692132075387
        }
      },
      "id": "5cf5b323-3b9c-479b-8502-acfc4f7915dd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might get a different response from above, but it doesn't matter what response you get, it will be based on the context given, not on previous answers.\n",
        "\n",
        "Until now we just have the same as the prior Notebook 03: results from Azure Search enhanced by OpenAI model, with no memory\n",
        "\n",
        "**Now let's add memory to it:**\n",
        "\n",
        "Reference: https://python.langchain.com/docs/modules/memory/how_to/adding_memory_chain_multiple_inputs"
      ],
      "metadata": {},
      "id": "035fa6e6-226c-400f-a504-30255385f43b"
    },
    {
      "cell_type": "code",
      "source": [
        "# memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\")\n",
        "\n",
        "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                        memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning has a wide range of use cases, including modeling epidemics to predict the spread of diseases and to learn prevention strategies<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[1]</a></sup><sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[3]</a></sup>, personalized music recommendation<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[2]</a></sup>, automatic feature engineering<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206177/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[4]</a></sup>, and computing lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[5]</a></sup>. Is there anything else I can help you with?"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1692132141355
        }
      },
      "id": "d98b876e-d264-48ae-b5ed-9801d6a9152b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we add a follow up question:\n",
        "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning has many use cases, including modeling epidemics to predict the spread of diseases and to learn prevention strategies<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[1]</a></sup><sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[3]</a></sup>, personalized music recommendation<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[2]</a></sup>, automatic feature engineering<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206177/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[4]</a></sup>, and computing lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[5]</a></sup>. \n\nTo summarize, reinforcement learning can be used for modeling epidemics and predicting the spread of diseases, personalized music recommendation, automatic feature engineering, and computing lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[1]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[2]</a></sup><sup><a href"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1692132183759
        }
      },
      "id": "bf28927b-d9ee-4412-bb07-13e055e832a7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Another follow up query\n",
        "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning has various use cases, including modeling epidemics to predict the spread of diseases and to learn prevention strategies<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[1]</a></sup><sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[3]</a></sup>, personalized music recommendation<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[2]</a></sup>, automatic feature engineering<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206177/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[4]</a></sup>, and computing lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[5]</a></sup>. \n\nTo summarize, reinforcement learning can be used for modeling epidemics and predicting the spread of diseases, personalized music recommendation, automatic feature engineering, and computing lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[1]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[2]</a></sup><sup><a href"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1692132225510
        }
      },
      "id": "3830b0b8-0ca2-4d0a-9747-f6273368002b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might get a different answer on the above cell, and it is ok, this bot is not yet well configured to answer any question that is not related to its knowledge base, including salutations.\n",
        "\n",
        "Let's check our memory to see that it's keeping the conversation"
      ],
      "metadata": {},
      "id": "111e732b-3c8c-4df3-8fcb-c3d01e7bec74"
    },
    {
      "cell_type": "code",
      "source": [
        "memory.buffer"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'memory' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmemory\u001b[49m\u001b[38;5;241m.\u001b[39mbuffer\n",
            "\u001b[0;31mNameError\u001b[0m: name 'memory' is not defined"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1693536213366
        }
      },
      "id": "1279692c-7eb0-4300-8a66-c7025f02c318"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using CosmosDB as persistent memory\n",
        "\n",
        "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wisg to provide recommendations. \n",
        "\n",
        "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
        "We will use a class in LangChain use CosmosDBChatMessageHistory, see [HERE](https://python.langchain.com/en/latest/_modules/langchain/memory/chat_message_histories/cosmos_db.html)"
      ],
      "metadata": {},
      "id": "87405173"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CosmosDB instance from langchain cosmos class.\n",
        "cosmos = CosmosDBChatMessageHistory(\n",
        "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
        "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
        "    )\n",
        "\n",
        "# prepare the cosmosdb instance\n",
        "cosmos.prepare_cosmos()"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1692132317522
        }
      },
      "id": "c7131daa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or Memory Object\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\",chat_memory=cosmos)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1692132326774
        }
      },
      "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing using our Question\n",
        "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                        memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning has several use cases, including modeling epidemics and predicting the spread of diseases<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[1]</a></sup>, personalized recommendation systems for music<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[2]</a></sup>, and learning mitigation policies for complex epidemiological models with a large state space<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[3]</a></sup>. Reinforcement learning can also be used for feature engineering, where it formalizes the feature engineering problem as an optimization problem over a Feature Transformation Graph (FTG)<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206177/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[4]</a></sup>. Lastly, reinforcement learning can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[5]</a></sup>."
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1692132358877
        }
      },
      "id": "27ceb47a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we add a follow up question:\n",
        "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "'I provided a summary of practical applications of reinforcement learning, including game playing, robotics, and industrial manufacturing<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">[1]</a></sup>. Anything else I can help you with?'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {},
      "id": "1a5ff826"
    },
    {
      "cell_type": "code",
      "source": [
        "# Another follow up query\n",
        "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning has several use cases, including modeling epidemics and predicting the spread of diseases<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[1]</a></sup>, personalized recommendation systems for music<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[2]</a></sup>, and learning mitigation policies for complex epidemiological models with a large state space<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[3]</a></sup>. Reinforcement learning can also be used for feature engineering, where it formalizes the feature engineering problem as an optimization problem over a Feature Transformation Graph (FTG)<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206177/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[4]</a></sup>. Lastly, reinforcement learning can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[5]</a></sup>."
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1692132380490
        }
      },
      "id": "be1620fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check our Azure CosmosDB to see the whole conversation\n"
      ],
      "metadata": {},
      "id": "cdc5ac98"
    },
    {
      "cell_type": "code",
      "source": [
        "#load message from cosmosdb\n",
        "cosmos.load_messages()\n",
        "cosmos.messages"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "[HumanMessage(content='Tell me some use cases for reinforcement learning?', additional_kwargs={}, example=False),\n AIMessage(content='Reinforcement learning has several use cases, including modeling epidemics and predicting the spread of diseases<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[1]</a></sup>, personalized recommendation systems for music<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[2]</a></sup>, and learning mitigation policies for complex epidemiological models with a large state space<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[3]</a></sup>. Reinforcement learning can also be used for feature engineering, where it formalizes the feature engineering problem as an optimization problem over a Feature Transformation Graph (FTG)<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206177/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[4]</a></sup>. Lastly, reinforcement learning can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[5]</a></sup>.', additional_kwargs={}, example=False),\n HumanMessage(content='Thank you', additional_kwargs={}, example=False),\n AIMessage(content='Reinforcement learning has several use cases, including modeling epidemics and predicting the spread of diseases<sup><a href=\"https://arxiv.org/pdf/2004.12959v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[1]</a></sup>, personalized recommendation systems for music<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206183/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[2]</a></sup>, and learning mitigation policies for complex epidemiological models with a large state space<sup><a href=\"https://arxiv.org/pdf/2003.13676v1.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[3]</a></sup>. Reinforcement learning can also be used for feature engineering, where it formalizes the feature engineering problem as an optimization problem over a Feature Transformation Graph (FTG)<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206177/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[4]</a></sup>. Lastly, reinforcement learning can be used to compute lockdown decisions for individual cities or regions while balancing health and economic considerations<sup><a href=\"https://arxiv.org/pdf/2003.14093v2.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[5]</a></sup>.', additional_kwargs={}, example=False)]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1692132391705
        }
      },
      "id": "e1d7688a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CosmosDB Memory](./images/cosmos-chathistory.png)"
      ],
      "metadata": {},
      "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
        "\n",
        "We added persitent memory using CosmosDB.\n",
        "\n",
        "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, it struggles to respond to prompts like: Hello, Thank you, Bye, What's your name, What's the weather and any other task that is not search in the knowledge base.\n",
        "\n"
      ],
      "metadata": {},
      "id": "6789cada-23a3-451a-a91a-0906ceb0bd14"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
        "\n",
        "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook 05 explains and solves the tabular problem and the concept of Agents"
      ],
      "metadata": {},
      "id": "c629ebf4-aced-45b7-a6a2-315810d37d48"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "6d4d9da4-3918-4da6-b235-a3320f0dcb12"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}