{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Queries with and without Azure OpenAI"
      ],
      "metadata": {},
      "id": "d59d527f-1100-45ff-b051-5f7c9029d94d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our Search Engine loaded **from two different data sources in two diferent indexes**, we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results.\n",
        "\n",
        "The idea is that a user can ask a question about Computer Science (first datasource/index) or about Covid (second datasource/index), and the engine will respond accordingly.\n",
        "This **Multi-Index** demo, mimics the scenario where a company loads multiple type of documents of different types and about completly different topics and the search engine must respond with the most relevant results."
      ],
      "metadata": {},
      "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up variables"
      ],
      "metadata": {},
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT\n",
        "from common.utils import model_tokens_limit, num_tokens_from_docs\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "# Demo Datasource Blob Storage. Change if using your own data\n",
        "DATASOURCE_SAS_TOKEN = \"?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\""
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1691849712127
        }
      },
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1691849716240
        }
      },
      "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Index Search queries"
      ],
      "metadata": {},
      "id": "9297d29b-1f61-4dce-858e-bf4272172dba"
    },
    {
      "cell_type": "code",
      "source": [
        "# Index that we are going to query (from Notebook 01 and 02)\n",
        "index1_name = \"cogsrch-index-files\"\n",
        "index2_name = \"cogsrch-index-csv\"\n",
        "indexes = [index1_name, index2_name]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "gather": {
          "logged": 1691849721180
        }
      },
      "id": "5a46e2d3-298a-4708-83de-9e108b1a117a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try questions that you think might be answered or addressed in computer science papers in 2020-2021 or that can be addressed by medical publications about COVID in 2020-201. Try comparing the results with the open version of ChatGPT.<br>\n",
        "The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
        "\n",
        "**Example Questions you can ask**:\n",
        "- What is CLP?\n",
        "- How Markov chains work?\n",
        "- What are some examples of reinforcement learning?\n",
        "- What are the main risk factors for Covid-19?\n",
        "- What medicine reduces inflamation in the lungs?\n",
        "- Why Covid doesn't affect kids that much compared to adults?\n",
        "- Does chloroquine really works against covid?"
      ],
      "metadata": {},
      "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"What is ISO 27018?\" "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1691849852170
        }
      },
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search on both indexes individually and aggragate results\n",
        "\n",
        "#### **Note**: \n",
        "In order to standarize the indexes, **there must be 7 mandatory fields present on each index**: `id, title, content, chunks, language, name, location`. This is so that each document can be treated the same along the code. Also, **all indexes must have a semantic configuration**."
      ],
      "metadata": {},
      "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf"
    },
    {
      "cell_type": "code",
      "source": [
        "agg_search_results = []\n",
        "\n",
        "for index in indexes:\n",
        "    url = os.environ['AZURE_SEARCH_ENDPOINT'] + '/indexes/'+ index + '/docs'\n",
        "    url += '?api-version={}'.format(os.environ['AZURE_SEARCH_API_VERSION'])\n",
        "    url += '&search={}'.format(QUESTION)\n",
        "    url += '&select=id,title,chunks,language,name,location'\n",
        "    url += '&$top=10'  # You can change this to anything you need/want\n",
        "    url += '&queryLanguage=en-us'\n",
        "    url += '&queryType=semantic'\n",
        "    url += '&semanticConfiguration=my-semantic-config'\n",
        "    url += '&$count=true'\n",
        "    url += '&speller=lexicon'\n",
        "    url += '&answers=extractive|count-3'\n",
        "    url += '&captions=extractive|highlight-false'\n",
        "\n",
        "    resp = requests.get(url, headers=headers)\n",
        "    print(url)\n",
        "    print(resp.status_code)\n",
        "\n",
        "    search_results = resp.json()\n",
        "    agg_search_results.append(search_results)\n",
        "    print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://cog-search-hf3ytnqvd5vby.search.windows.net/indexes/cogsrch-index-files/docs?api-version=2023-07-01-Preview&search=What is ISO 27018?&select=id,title,chunks,language,name,location&$top=10&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n200\nResults Found: 8, Results Returned: 8\nhttps://cog-search-hf3ytnqvd5vby.search.windows.net/indexes/cogsrch-index-csv/docs?api-version=2023-07-01-Preview&search=What is ISO 27018?&select=id,title,chunks,language,name,location&$top=10&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n200\nResults Found: 48650, Results Returned: 10\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1691849859597
        }
      },
      "id": "faf2e30f-e71f-4533-ab52-27d048b80a89"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the top results (from both searches) based on the score"
      ],
      "metadata": {
        "tags": []
      },
      "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389"
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML('<h4>Top Answers</h4>'))\n",
        "\n",
        "for search_results in agg_search_results:\n",
        "    for result in search_results['@search.answers']:\n",
        "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
        "            display(HTML('<h5>' + 'Answer - score: ' + str(round(result['score'],2)) + '</h5>'))\n",
        "            display(HTML(result['text']))\n",
        "            \n",
        "print(\"\\n\\n\")\n",
        "display(HTML('<h4>Top Results</h4>'))\n",
        "\n",
        "content = dict()\n",
        "ordered_content = OrderedDict()\n",
        "\n",
        "\n",
        "for search_results in agg_search_results:\n",
        "    for result in search_results['value']:\n",
        "        content[result['id']]={\n",
        "                                \"title\": result['title'],\n",
        "                                \"chunks\": result['chunks'],\n",
        "                                \"language\": result['language'], \n",
        "                                \"name\": result['name'], \n",
        "                                \"location\": result['location'] ,\n",
        "                                \"caption\": result['@search.captions'][0]['text'],\n",
        "                                \"score\": result['@search.rerankerScore']               \n",
        "                                }\n",
        "    \n",
        "#After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
        "for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
        "    ordered_content[id] = content[id]\n",
        "    url = str(ordered_content[id]['location']) + DATASOURCE_SAS_TOKEN\n",
        "    title = str(ordered_content[id]['title']) if (ordered_content[id]['title']) else ordered_content[id]['name']\n",
        "    score = str(round(ordered_content[id]['score'],2))\n",
        "    display(HTML('<h5><a href=\"'+ url + '\">' + title + '</a> - score: '+ score + '</h5>'))\n",
        "    display(HTML(ordered_content[id]['caption']))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Top Answers</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>Answer - score: 0.99</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "ISO 27018 establishes cloud-specific control objectives and guidelines for PII in accordance with the   privacy principles in ISO 29100."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Top Results</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/Microsoft%20Azure%20Compliance%20Offerings%20March%202023.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Microsoft Azure Compliance Offerings March 2023.pdf</a> - score: 3.59</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "ISO 27018 establishes cloud-specific control objectives and guidelines for PII in accordance with the   privacy principles in ISO 29100."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/Microsoft%20Azure%20-%20Compliance%20Offerings%20(March%202023).pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Microsoft Azure - Compliance Offerings (March 2023).pdf</a> - score: 1.41</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "• industry specific: compliance offerings are intended to address the needs of customers subject   to various industry regulations such as those in financial services, healthcare and life sciences,   media and entertainment, education, etc.  azure is not subject directly to oversight by these   regulators; however, azure can help customers meet …"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://doi.org/10.1101/2020.04.27.065383?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">In silico design and validation of commercial kit GPS™ CoVID-19 dtec-RT-qPCR Test under criteria of UNE/EN ISO 17025:2005 and ISO/IEC 15189:2012</a> - score: 1.27</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "The empirical validation parameters specificity (inclusivity/exclusivity), quantitative phase analysis (10-106 copies), reliability (repeatability/reproducibility) and sensitivity (detection/quantification limits) were evaluated for a minimum of 10-15 assays."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://doi.org/10.3174/ajnr.a4421; https://www.ncbi.nlm.nih.gov/pubmed/26228892/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Outcome Differences between Intra-Arterial Iso- and Low-Osmolality Iodinated Radiographic Contrast Media in the Interventional Management of Stroke III Trial.</a> - score: 1.15</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Iso-osmolal iodixanol (290 mOsm/kg H2O) infusion demonstrated smaller infarcts and less intracranial hemorrhage compared with low-osmolal iopamidol and saline. No studies comparing iodinated radiographic contrast media in human stroke have been performed, to our knowledge."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://doi.org/10.1007/s10396-018-0861-6; https://www.ncbi.nlm.nih.gov/pubmed/29362966/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Fusion imaging with contrast-enhanced ultrasonography for evaluating the early therapeutic efficacy of radiofrequency ablation for small hypervascular hepatocellular carcinomas with iso-echoic or unclear margins on conventional ultrasonography.</a> - score: 1.08</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Fusion imaging with contrast-enhanced ultrasonography for evaluating the early therapeutic efficacy of radiofrequency ablation for small hypervascular hepatocellular carcinomas with iso-echoic or unclear margins on conventional ultrasonography.."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/17046264/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Design, synthesis, and biological evaluation of novel iso-D-2',3'-dideoxy-3'-fluorothianucleoside derivatives.</a> - score: 1.04</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Novel iso-d-2',3'-dideoxythianucleoside derivatives 1-4 were designed and asymmetrically synthesized as a bioisostere of lamivudine to search for new anti-HIV agents. The information about using sulfur participation occurred on DAST fluorination and Mitsunobu reaction will be of great help in synthesizing sulfur-containing compounds."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/12626073/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Subsensitivity to beta-adrenergic stimulation in atria from rats infested with Syphacia sp.</a> - score: 0.87</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "In this study, we analysed the responsiveness to beta-adrenergic stimulation by isoproterenol (ISO) of left atria isolated from Syphacia-infested (SYPH) and control, non-infested adult male Wistar rats (CONT). In the non-infested animals, ISO pD(2) was not significantly changed by ivermectin treatment."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://doi.org/10.4142/jvs.2018.19.3.426; https://www.ncbi.nlm.nih.gov/pubmed/29169225/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Comparison of the effects of isoflurane versus propofol-remifentanil anesthesia on oxygen delivery during thoracoscopic lung lobectomy with one-lung ventilation in dogs.</a> - score: 0.84</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "This study compared effects of isoflurane inhalation (ISO) and propofol-remifentanil combined total intravenous anesthesia (TIVA) on oxygenation during thoracoscopic lung lobectomy with 30-min one-lung ventilation (1LV)."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7123200/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Design of Real-time Systems for QoS</a> - score: 0.78</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Design of Real-time Systems for QoS. It was discovered early, that in order to achieve the desired QoS properties a design methodology for real-time systems has to include appropriate measures to ensure that the QoS criteria are considered during the entire life-cycle."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/COVID-19%20Case%20Notes%20-%202023.docx?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">COVID-19 Case Notes - 2023.docx</a> - score: 0.72</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "· Additional notes regarding this update are as follows: · Finalized data are based on a defined MMWR Year, which is an epidemiologic year used by the Centers for Disease Control’s National Notifiable Diseases Surveillance System (NNDSS) for disease incidence reporting and publishing."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://doi.org/10.4103/1995-7645.277795?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Novel coronavirus (2019-nCoV) update: What we know and what is unknown</a> - score: 0.65</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "preliminary clinical features indicated that most of the infected patients were men with underlying diseases (comorbidities) including diabetes, hypertension, cardiovascular disease, chronic obstructive pulmonary disease, malignancy and chronic liver disease[6] patient presented with fever, cough, myalgia, sputum production, headache, …"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://doi.org/10.1007/s00203-020-01892-1; https://www.ncbi.nlm.nih.gov/pubmed/32388821/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Herbaspirillum camelliae sp. nov., a novel endophytic bacterium isolated from Camellia sinensis L.</a> - score: 0.61</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "This strain is microaerobic, gram-negative and non-pigmented, and its cells are rod shaped, with a polar flagellum. It grew optimally at 34-37 °C, pH 5.0-8.0 and 0-1.5% NaCl (w/v). The G + C content of its genomic DNA was 62.36 mol%. C16:0, iso-C15:0, iso-C17:0, anteiso-C15:0 and anteiso-C17:0 were major fatty acids."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7123365/?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Medical Technology Management in Hospital Certification in Mexico</a> - score: 0.61</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Medical Technology Management in Hospital Certification in Mexico. Mexican health policy is promoting the quality of health services by hospital certification meeting the NMX-CC standards family, which is the Mexican equivalent of the ISO 9000 standards family. These standards can help both product- and service-oriented organizations achieve standards of quality that are recognized and respected throughout the world in developing a quality management system (QMS).."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/covid.png?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">covid.png</a> - score: 0.47</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "The Texas SARS-COV-2 genomic sequencing data includes data provided by the CDC's commercial partner laboratories as a part of the national SARS-COV-2 genomic surveillance program, sequencing conducted at academic and commercial laboratories, and Texas Department of State Health Services Austin Laboratory's genomic sequencing."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/SQL_Server_2019_Licensing_guide%20(2).pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">SQL_Server_2019_Licensing_guide (2).pdf</a> - score: 0.4</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "A minimum of four core licenses is required for each physical processor on the server. To determine and acquire the correct number of core licenses needed, customers must:   1. Count the total number of physical cores in the server. 2. Purchase the appropriate number of core licenses required for the server."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/Data&AI%20-%20Azure%20SQL%20Database%20Managed%20Instance_Technical%20overview%20(1).pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Azure SQL Database Managed Instance - Technical Overview</a> - score: 0.29</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "this step helps that automate and guide you through the performance, and maximize roi with free(\") cost map dependencies across applications and migration journey while helping ensure management tools analyze their priority for migration minimal business impact on-premises learn how migrating to azure yields powerful results chat with an expert …"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/Software-Assurance-MSCOM-Frequently-Asked-Questions.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">Software-Assurance-MSCOM-Frequently-Asked-Questions</a> - score: 0.25</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Azure Active Directory is an identity and access management solution. It is an identity service that helps the   Microsoft Workplace Discount Program  validate your organization’s employee purchase eligibility."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/adventureworks_poc.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\">adventureworks_poc.pdf</a> - score: 0.13</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Microsoft       Azure Information       Protection        This is a protected document. You can view it using a supported PDF   reader app.       Open in the app:                        Learn about PDF documents protected by   Microsoft Azure Information Protection                 Microsoft respects your privacy."
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1691849885072
        }
      },
      "id": "9e938337-602d-4b61-8141-b8c92a5d91da"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments on Query results"
      ],
      "metadata": {},
      "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above the semantic search feature of Azure Cognitive Search service is good. It gives us some answers and also the top results with the corresponding file and the paragraph where the answers is possible located.\n",
        "\n",
        "Let's see if we can make this better with Azure OpenAI"
      ],
      "metadata": {},
      "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Azure OpenAI\n",
        "\n",
        "To use OpenAI to get a better answer to our question, the thought process is: let's send the the documents of the search result to the GPT model and let it understand the document's content and provide a better response.\n",
        "\n",
        "We will use a genius library call **LangChain** that wraps a lot of boiler plate code.\n",
        "Langchain is one library that does a lot of the prompt engineering for us under the hood, for more information see [here](https://python.langchain.com/en/latest/index.html)"
      ],
      "metadata": {},
      "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A gentle intro to chaining LLMs and prompt engineering"
      ],
      "metadata": {},
      "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chains are what you get by connecting one or more large language models (LLMs) in a logical way. (Chains can be built of entities other than LLMs but for now, let’s stick with this definition for simplicity).\n",
        "\n",
        "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
        "\n",
        "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
        "\n",
        "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
        "\n",
        "Here’s an example:"
      ],
      "metadata": {},
      "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1691850110217
        }
      },
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our LLM model\n",
        "# Make sure you have the deployment named \"gpt-35-turbo\" for the model \"gpt-35-turbo (0301)\". \n",
        "# Use \"gpt-4\" if you have it available.\n",
        "MODEL = \"gpt-35-turbo\" # options: gpt-35-turbo, gpt-4, gpt-4-32k\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0, max_tokens=500)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1691850113563
        }
      },
      "id": "13df9247-e784-4e04-9475-55e672efea47"
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we create a simple prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"language\"],\n",
        "    template='Answer the following question: \"{question}\". Give your response in {language}',\n",
        ")\n",
        "\n",
        "print(prompt.format(question=QUESTION, language=\"French\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Answer the following question: \"What is ISO 27018?\". Give your response in French\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1691850129223
        }
      },
      "id": "7b0520b9-83b2-49fd-ad84-624cb0f15ce1"
    },
    {
      "cell_type": "code",
      "source": [
        "# And finnaly we create our first generic chain\n",
        "chain_chat = LLMChain(llm=llm, prompt=prompt)\n",
        "chain_chat({\"question\": QUESTION, \"language\": \"French\"})"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "{'question': 'What is ISO 27018?',\n 'language': 'French',\n 'text': \"ISO 27018 est une norme internationale qui établit des lignes directrices pour la protection des informations personnelles identifiables (PII) dans le cloud computing. Elle fournit des mesures de sécurité pour les fournisseurs de services cloud qui traitent des données personnelles, telles que la confidentialité, l'intégrité et la disponibilité des données. Cette norme est conçue pour aider les organisations à se conformer aux lois et réglementations en matière de protection des données, telles que le Règlement général sur la protection des données (RGPD) de l'Union européenne.\"}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1691850140512
        }
      },
      "id": "dcc7dae3-6b88-4ea6-be43-b178ebc559dc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
        "\n",
        "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
      ],
      "metadata": {},
      "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The second type of Chains are Utility:**\n",
        "\n",
        "* Utility — These are specialized chains, comprised of many LLMs to help solve a specific task. For example, LangChain supports some end-to-end chains (such as [QA_WITH_SOURCES](https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html) for QnA Doc retrieval, Summarization, etc) and some specific ones (such as GraphQnAChain for creating, querying, and saving graphs). \n",
        "\n",
        "We will look at one specific chain called **qa_with_sources** in this workshop for digging deeper and solve our use case of enhancing the results of Azure Cognitive Search."
      ],
      "metadata": {
        "tags": []
      },
      "id": "12c48038-b1af-4228-8ffb-720e554fd3b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "But before dealing with the utility chain needed, we need to deal first with this problem: **the content of the search result files is or can be very lengthy, more than the allowed tokens allowed by the GPT Azure OpenAI models**. So what we need to do is: split in chunks, vectorize those chunks and do a vector semantic search to get the top chunks in order to provide the best and not too lenghy context to the LLM.\n",
        "\n",
        "Notice that **the documents chunks are already done in Azure Search**. *ordered_content* dictionary (created a few cells above) contains the pages (chunks) of each document. So we don't really need to chunk them again, but we still need to make sure that we can be as fast as possible and that we are below the max allowed input token limits of our selected OpenAI model."
      ],
      "metadata": {},
      "id": "b0454ddb-44d8-4fa9-929a-5e5563dd28f8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each of the results chunks and create a LangChain Document class to use further in the pipeline\n",
        "docs = []\n",
        "for key,value in ordered_content.items():\n",
        "    for page in value[\"chunks\"]:\n",
        "        location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
        "        docs.append(Document(page_content=page, metadata={\"source\": location+DATASOURCE_SAS_TOKEN}))\n",
        "        \n",
        "print(\"Number of chunks:\",len(docs))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of chunks: 115\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1691850190471
        }
      },
      "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need now to calculate the number of tokens for all the chunks combined to decide what to do:\n",
        "1) Should we embed to vectors and do cosine similarity because there is too much data to fit on the prompt as context?\n",
        "2) What happens if the amount of chunks is too big? how do we keep the response time on-check?"
      ],
      "metadata": {},
      "id": "345d35f6-b7c8-4fda-a9e2-94a7da16a18e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate number of tokens of our docs\n",
        "if(len(docs)>0):\n",
        "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
        "    num_tokens = num_tokens_from_docs(docs) # this is a custom function we created in common/utils.py\n",
        "    print(\"Custom token limit for\", MODEL, \":\", tokens_limit)\n",
        "    print(\"Combined docs tokens count:\",num_tokens)\n",
        "        \n",
        "else:\n",
        "    print(\"NO RESULTS FROM AZURE SEARCH\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Custom token limit for gpt-35-turbo : 2500\nCombined docs tokens count: 122057\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1691850198515
        }
      },
      "id": "62bd5169-f273-4c66-a91b-6de990dad244"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, depending of the amount of chunks/pages returned from the search result, which is very related to the size of the documents returned, we need to make some decisions to keep the speed of the response from Azure OpenAI at reasonable levels.\n",
        "\n",
        "**The logic is**: if there is less than X chunks (of 5000 chars each) to vectorize, then we use OpenAI models in all of them, which currently don't offer batch processing (but it will soon), but if there is more than X chunks we have to trim the number of chunks to the first X, otherwise large documents can take minutes to vectorize.\n",
        "\n",
        "**Note**, this is a temporary solution. Once Vector Capabilities in Azure Cognitive Search is in Public Preview, then we can vectorize once, store, then retrieve them again when needed.\n"
      ],
      "metadata": {},
      "id": "c5403dee-a4c4-420c-9819-68151d973695"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "chunks_limit = 100 # This is the limit of how many chunks are we willing to take in order to keep the response fairly quick\n",
        "\n",
        "if num_tokens > tokens_limit:\n",
        "    # Select the Embedder model\n",
        "    embedder = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1) \n",
        "    print(\"Initial Number of chunks:\",len(docs))\n",
        "    if len(docs) > chunks_limit:\n",
        "        docs = docs[:chunks_limit]\n",
        "        print(\"Truncated Number of chunks:\",len(docs))\n",
        "    \n",
        "    # Create our in-memory vector database index from the chunks given by Azure Search.\n",
        "    # We are using FAISS. https://ai.facebook.com/tools/faiss/\n",
        "    db = FAISS.from_documents(docs, embedder)\n",
        "    top_docs = db.similarity_search(QUESTION, k=4)  # Return the top 4 documents\n",
        "    \n",
        "    # Now we need to recalculate the tokens count of the top results from similarity vector search\n",
        "    # in order to select the chain type: stuff (all chunks in one prompt) or \n",
        "    # map_reduce (multiple calls to the LLM to summarize/reduce the chunks and then combine them)\n",
        "    \n",
        "    num_tokens = num_tokens_from_docs(top_docs)\n",
        "    print(\"Token count after similarity search:\", num_tokens)\n",
        "    chain_type = \"map_reduce\" if num_tokens > tokens_limit else \"stuff\"\n",
        "    \n",
        "else:\n",
        "    # if total tokens is less than our limit, we don't need to vectorize and do similarity search\n",
        "    top_docs = docs\n",
        "    chain_type = \"stuff\"\n",
        "    \n",
        "print(\"Chain Type selected:\", chain_type)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Initial Number of chunks: 115\nTruncated Number of chunks: 100\nToken count after similarity search: 4648\nChain Type selected: map_reduce\nCPU times: user 407 ms, sys: 16.2 ms, total: 423 ms\nWall time: 5.39 s\n"
        }
      ],
      "execution_count": 13,
      "metadata": {},
      "id": "a03f1f10-32b0-4c1e-8a0e-eee1b1d29ce7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we already have the top most similar chunks (in order of relevance) in **top_docs**\n",
        "\n",
        "Now we need Azure OpenAI GPT model to understand these top chunks and provide us an answer to the question."
      ],
      "metadata": {},
      "id": "17247488-7d14-4178-9add-31eb1afcbcbe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this task, we need to come back to the Utility Chain: **qa_with_sources** that we mentioned before. See [HERE](https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html) for reference.\n",
        "\n",
        "We created our own custom prompts so we can add translation to a specified language. But, for more information on the different types of prompts for this utility chain please see [HERE](https://github.com/hwchase17/langchain/tree/master/langchain/chains/question_answering)\n"
      ],
      "metadata": {},
      "id": "1f8c6ad1-82b8-4fd8-80a3-0276b81d7231"
    },
    {
      "cell_type": "code",
      "source": [
        "if chain_type == \"stuff\":\n",
        "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
        "                                       prompt=COMBINE_PROMPT)\n",
        "elif chain_type == \"map_reduce\":\n",
        "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
        "                                       question_prompt=COMBINE_QUESTION_PROMPT,\n",
        "                                       combine_prompt=COMBINE_PROMPT,\n",
        "                                       return_intermediate_steps=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1691850270765
        }
      },
      "id": "3ab16c86-9863-4001-89af-6819c6f3240a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment the below line if you want to check our custom COMBINE_PROMPT\n",
        "print(chain.combine_document_chain.llm_chain.prompt.template)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\nThese are examples of how you must provide the answer:\n\n--> Beginning of examples\n\n=========\nQUESTION: Which state/country's law governs the interpretation of the contract?\n=========\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\nSource: https://xxx.com/article1.pdf?s=casdfg&category=ab&sort=asc&page=1\n\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n\n11.9 No Third-Party Beneficiaries.\nSource: https://yyyy.com/article2.html?s=lkhljkhljk&category=c&sort=asc\n\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\nSource: https://yyyy.com/article3.csv?s=kjsdhfd&category=c&sort=asc&page=2\n\nContent: The terms of this Agreement shall be subject to the laws of Manchester, England, and any disputes arising from or relating to this Agreement shall be exclusively resolved by the courts of that state, except where either party may seek an injunction or other legal remedy to safeguard their Intellectual Property Rights.\nSource: https://ppp.com/article4.pdf?s=lkhljkhljk&category=c&sort=asc\n=========\nFINAL ANSWER IN English: This Agreement is governed by English law, specifically the laws of Manchester, England<sup><a href=\"https://xxx.com/article1.pdf?s=casdfg&category=ab&sort=asc&page=1\" target=\"_blank\">[1]</a></sup><sup><a href=\"https://ppp.com/article4.pdf?s=lkhljkhljk&category=c&sort=asc\" target=\"_blank\">[2]</a></sup>. \n Anything else I can help you with?.\n\n=========\nQUESTION: What did the president say about Michael Jackson?\n=========\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n\nLast year COVID-19 kept us apart. This year we are finally together again. \n\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n\nWith a duty to one another to the American people to the Constitution. \n\nAnd with an unwavering resolve that freedom will always triumph over tyranny..\nSource: https://fff.com/article23.pdf?s=wreter&category=ab&sort=asc&page=1\n\nContent: And we won’t stop. \n\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \n\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n\nOfficer Mora was 27 years old. \n\nOfficer Rivera was 22. \n\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \n\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\nSource: https://jjj.com/article56.pdf?s=sdflsdfsd&category=z&sort=desc&page=3\n\nContent: And I will use every tool at our disposal to protect American businesses and consumers. \n\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \n\nBut I want you to know that we are going to be okay.\nSource: https://vvv.com/article145.pdf?s=sfsdfsdfs&category=z&sort=desc&page=3\n\nContent: More support for patients and families. \n\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \n\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \n\nA unity agenda for the nation. \n\nWe can do this. \n\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \n\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \n\nNow is the hour. \n\nOur moment of responsibility. \n\nOur test of resolve and conscience, of history itself. \n\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \n\nWell I know this nation.\nSource: https://uuu.com/article15.pdf?s=lkhljkhljk&category=c&sort=asc\n=========\nFINAL ANSWER IN English: The president did not mention Michael Jackson.\n\n<-- End of examples\n\n# Instructions:\n- Given the following extracted parts of a long document and a question, create a final answer with references. \n- You can only provide numerical references to documents, using this format: <sup><a href=\"url?query_parameters\" target=\"_blank\">[number]</a></sup>.\n- Reference document's url can include query parameters, for example: \"https://example.com/search?query=apple&category=fruits&sort=asc&page=1\". On these cases, **you must** include que query references on the document url, using this format: <sup><a href=\"url?query_parameters\" target=\"_blank\">[number]</a></sup>.\n- If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n- Respond in {language}.\n\n=========\nQUESTION: {question}\n=========\n{summaries}\n=========\nFINAL ANSWER IN {language}:\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1691850281194
        }
      },
      "id": "28926219-74c2-4538-8493-129463ac40a7"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Try with other language as well\n",
        "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"English\"})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 22.9 ms, sys: 115 µs, total: 23.1 ms\nWall time: 12.9 s\n"
        }
      ],
      "execution_count": 16,
      "metadata": {},
      "id": "a1e619b8-1dcf-431b-8aad-f1696a09c2ac"
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(response['output_text']))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "ISO 27018 is the first international code of practice for cloud privacy that provides guidelines based on ISO 27002 guidelines and best practices for information security management. It gives specific guidance to cloud service providers acting as processors of personally identifiable information (PII) on assessing risks and implementing state-of-the-art controls for protecting PII. ISO 27018 establishes cloud-specific control objectives and guidelines for PII in accordance with the privacy principles in ISO 29100<sup><a href=\"https://njonpdadls3.blob.core.windows.net/gptdata/Microsoft%20Azure%20Compliance%20Offerings%20March%202023.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2023-11-29T01:50:59Z&st=2023-05-10T16:50:59Z&spr=https&sig=ZT7MLy%2BnlvAxUKKj5v0RwoWObXaab3gO4ec2%2Fci6iL0%3D\" target=\"_blank\">[1]</a></sup>."
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1691850313230
        }
      },
      "id": "681fe1de-e37c-4355-accc-6dd15b6a310a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you want to inspect the results from map_reduce chain type, each top similar chunk summary (k=4 by default)\n",
        "\n",
        "# if chain_type == \"map_reduce\":\n",
        "#     for step in response['intermediate_steps']:\n",
        "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {},
      "id": "11345374-6420-4b36-b061-795d2a804c85"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
        "- Azure Cognitive Search give us the top results (context)\n",
        "- Azure OpenAI takes these results and understand the content and uses it as context to give the best answer\n",
        "- Best of two worlds!"
      ],
      "metadata": {},
      "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "We just added a smart layer on top of Azure Cognitive Search. This is the backend for a GPT Smart Search Engine.\n",
        "\n",
        "However, we are missing something: **How to have a conversation with this engine?**\n",
        "\n",
        "On the next Notebook, we are going to understand the concept of **memory**. This is necessary in order to have a chatbot that can establish a conversation with the user. Without memory, there is no real conversation."
      ],
      "metadata": {},
      "id": "fdc6e2fe-1c34-4952-99ad-14940f022379"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}